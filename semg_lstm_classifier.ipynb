{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zW_pPY2u6wLm",
    "outputId": "1c375157-6d5a-493e-e6a9-3caf137cebf1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# !pip install fastparquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "id": "yG3ZVgMwhbbi",
    "outputId": "c82081a5-8337-4ad0-b78d-f4be1050f453"
   },
   "outputs": [],
   "source": [
    "# Read the processed dataset.\n",
    "semg_df = pd.read_parquet('/content/drive/MyDrive/sEMG-HAR/semg_extracted_scalar_features_only', engine='fastparquet')\n",
    "\n",
    "semg_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LefM5NIXhtQH",
    "outputId": "76683778-3b7d-4547-cee8-bdf45c7cbab8"
   },
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "\n",
    "# print(semg_df.columns)\n",
    "\n",
    "X = semg_df.drop(columns=['activity']).astype('float32')\n",
    "y = semg_df['activity']\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# One-hot encoding for the labels\n",
    "y = to_categorical(y-1, num_classes=21)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3aX-yKnhQwQ"
   },
   "source": [
    "# Simple LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXq4KSOHrsKj",
    "outputId": "78a0df69-d5d3-433d-fce8-c039e6ce18ec"
   },
   "outputs": [],
   "source": [
    "\n",
    "# LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))  # 50 units in the LSTM layer\n",
    "\n",
    "model.add(Dropout(0.5))  # dropout layer with dropout rate of 0.5\n",
    "\n",
    "model.add(Dense(21, activation='softmax'))  # 21 units in the output layer for 21 classes\n",
    "\n",
    "# Compile and fit the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "H9cFkq64vs01",
    "outputId": "f3b9664e-bf0c-4b94-8c2b-a8e7a23bff40"
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss', color=color)\n",
    "line1, = ax1.plot(history.history['loss'], color=color, label='Train Loss')\n",
    "line2, = ax1.plot(history.history['val_loss'], color=color, linestyle='dashed', label='Val Loss')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Accuracy', color=color)\n",
    "line3, = ax2.plot(history.history['accuracy'], color=color, label='Train Acc')\n",
    "line4, = ax2.plot(history.history['val_accuracy'], color=color, linestyle='dashed', label='Val Acc')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Added this line\n",
    "lns = [line1, line2, line3, line4]\n",
    "ax1.legend(handles=lns, loc='center right')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2LfNbobhIlT"
   },
   "source": [
    "Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-h5039ayvSj",
    "outputId": "ba8eaf89-d109-4f61-f0e0-d38615b11021"
   },
   "outputs": [],
   "source": [
    "#Stacked LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(50))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(21, activation='softmax'))\n",
    "\n",
    "# Compile and fit the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pHKmClsewUTn",
    "outputId": "493f4615-a64d-4cb5-c65f-79188d2fe971"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "hsj4f25jha7E",
    "outputId": "622833a4-c5da-45d6-e96f-167f42e31f29"
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss', color=color)\n",
    "line1, = ax1.plot(history.history['loss'], color=color, label='Train Loss')\n",
    "line2, = ax1.plot(history.history['val_loss'], color=color, linestyle='dashed', label='Val Loss')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Accuracy', color=color)\n",
    "line3, = ax2.plot(history.history['accuracy'], color=color, label='Train Acc')\n",
    "line4, = ax2.plot(history.history['val_accuracy'], color=color, linestyle='dashed', label='Val Acc')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Added this line\n",
    "lns = [line1, line2, line3, line4]\n",
    "ax1.legend(handles=lns, loc='center right')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIKMJamMkwru"
   },
   "source": [
    "Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BkSwRgWHhbc_",
    "outputId": "7612d5ec-3f39-4743-d325-1d85d9a34809"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(42), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(21, activation='softmax'))\n",
    "\n",
    "# Compile and fit the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=350, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "48LoGcxnk45q",
    "outputId": "c81fa137-c360-4bc4-ed6b-a057fa050eb1"
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss', color=color)\n",
    "line1, = ax1.plot(history.history['loss'], color=color, label='Train Loss')\n",
    "line2, = ax1.plot(history.history['val_loss'], color=color, linestyle='dashed', label='Val Loss')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Accuracy', color=color)\n",
    "line3, = ax2.plot(history.history['accuracy'], color=color, label='Train Acc')\n",
    "line4, = ax2.plot(history.history['val_accuracy'], color=color, linestyle='dashed', label='Val Acc')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Added this line\n",
    "lns = [line1, line2, line3, line4]\n",
    "ax1.legend(handles=lns, loc='center right')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1Gr_KPnnOaO"
   },
   "source": [
    "MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOAYOnefqZlg",
    "outputId": "107fb58f-eab1-49ee-d1f1-2f26539a73ff"
   },
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "\n",
    "# print(semg_df.columns)\n",
    "\n",
    "X = semg_df.drop(columns=['activity']).astype('float32')\n",
    "y = semg_df['activity']\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# One-hot encoding for the labels\n",
    "y = to_categorical(y-1, num_classes=21)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "# # Reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "# X_train = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "# X_test = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VPCZNdQQk5LC",
    "outputId": "13dc9f75-96a3-4998-c468-cb1c7a1d956f"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# MLP model with dropout and L2 regularization\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01), input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(21, activation='softmax'))  # 21 units in the output layer for 21 classes\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
    "\n",
    "# Compile and fit the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=750, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "dS6of0M0nUeQ",
    "outputId": "9303b713-9da9-47f6-82f3-1e76d0c349c7"
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss', color=color)\n",
    "line1, = ax1.plot(history.history['loss'], color=color, label='Train Loss')\n",
    "line2, = ax1.plot(history.history['val_loss'], color=color, linestyle='dashed', label='Val Loss')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Accuracy', color=color)\n",
    "line3, = ax2.plot(history.history['accuracy'], color=color, label='Train Acc')\n",
    "line4, = ax2.plot(history.history['val_accuracy'], color=color, linestyle='dashed', label='Val Acc')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Added this line\n",
    "lns = [line1, line2, line3, line4]\n",
    "ax1.legend(handles=lns, loc='center right')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmKzYa85m9j8"
   },
   "source": [
    "FNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXq5lI4npLdJ",
    "outputId": "0375a0ee-40b6-4494-917e-167882f0174b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# # Split the data into training and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(\"number of columns:\", len(X_train.columns))\n",
    "\n",
    "# Build the FNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(42, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(42, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(21, activation='softmax')\n",
    "])\n",
    "\n",
    "initial_learning_rate = 0.01\n",
    "epochs = 350\n",
    "batch_size = 32\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "Sg8OMKBEz7zz",
    "outputId": "26d1100c-75f5-431e-9f9b-5a382d101ccf"
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss', color=color)\n",
    "line1, = ax1.plot(history.history['loss'], color=color, label='Train Loss')\n",
    "line2, = ax1.plot(history.history['val_loss'], color=color, linestyle='dashed', label='Val Loss')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Accuracy', color=color)\n",
    "line3, = ax2.plot(history.history['accuracy'], color=color, label='Train Acc')\n",
    "line4, = ax2.plot(history.history['val_accuracy'], color=color, linestyle='dashed', label='Val Acc')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Added this line\n",
    "lns = [line1, line2, line3, line4]\n",
    "ax1.legend(handles=lns, loc='center right')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5yxl3hdxxBt"
   },
   "source": [
    "Simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LEVK_r565FbU",
    "outputId": "9f55fb5a-4172-476e-bbb2-9425ada87143"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming you have X_train and y_train as your training data and labels\n",
    "\n",
    "# Reshape the time domain features to be treated as 2D images\n",
    "# This assumes X_train has shape: (num_samples, num_features_per_sample)\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[2])\n",
    "\n",
    "# Create a function to apply data augmentation manually\n",
    "def augment_data(X, y, num_augmentations=5):\n",
    "    num_samples, num_features = X.shape\n",
    "    augmented_X = []\n",
    "    augmented_y = []\n",
    "    for i in range(num_samples):\n",
    "        # Original sample\n",
    "        augmented_X.append(X[i])\n",
    "        augmented_y.append(y[i])\n",
    "\n",
    "        # Data augmentation: Apply random rotations, shifts, or other transformations here\n",
    "        for _ in range(num_augmentations):\n",
    "            # For example, you can apply random rotations of +/- 20 degrees\n",
    "            augmented_X.append(np.rot90(X[i].reshape(1, -1), k=np.random.choice([1, 2, 3]), axes=(1, 0)).flatten())\n",
    "            augmented_y.append(y[i])\n",
    "\n",
    "            # Add more data augmentation techniques here, if needed\n",
    "\n",
    "    return np.array(augmented_X), np.array(augmented_y)\n",
    "\n",
    "# Apply data augmentation to the training data\n",
    "num_augmentations = 50\n",
    "X_train_augmented, y_train_augmented = augment_data(X_train_reshaped, y_train, num_augmentations=num_augmentations)\n",
    "\n",
    "# Reshape augmented data to match the model's input shape\n",
    "X_train_augmented = X_train_augmented.reshape(-1, 1, X_train.shape[2])\n",
    "print(X_train_augmented.shape)\n",
    "# # Train the model using the augmented data\n",
    "# model.fit(X_train_augmented, y_train_augmented, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rAAX2Itn0wBa",
    "outputId": "9724174c-e239-40b0-ed9f-e61f0855588b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1, 552))) # Flattening the input as it has only one timestep\n",
    "model.add(Dense(128, activation='relu'))  # Adding another hidden layer with 64 units\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(21, activation='softmax')) # Output layer with 21 units for 21 classes\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_augmented, y_train_augmented, epochs=50, batch_size=batch_size, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "EaZd0gFkx8Af",
    "outputId": "abb84d2c-eee5-4406-fcf8-4fc4155480e5"
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss', color=color)\n",
    "line1, = ax1.plot(history.history['loss'], color=color, label='Train Loss')\n",
    "line2, = ax1.plot(history.history['val_loss'], color=color, linestyle='dashed', label='Val Loss')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Accuracy', color=color)\n",
    "line3, = ax2.plot(history.history['accuracy'], color=color, label='Train Acc')\n",
    "line4, = ax2.plot(history.history['val_accuracy'], color=color, linestyle='dashed', label='Val Acc')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Added this line\n",
    "lns = [line1, line2, line3, line4]\n",
    "ax1.legend(handles=lns, loc='center right')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaHkxHkH2ssa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
